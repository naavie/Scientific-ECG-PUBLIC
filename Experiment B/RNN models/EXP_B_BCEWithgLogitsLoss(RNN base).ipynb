{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZivDbv549fpt"
      },
      "source": [
        "# Experiment B\n",
        "\n",
        "Objective: Train a 1D-CNN Image Encoder on the SPH dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQZ58CmjDrNb"
      },
      "source": [
        "Split the data into train, validation, test subsets.\n",
        "\n",
        "Example code for finding f1_thresholds\n",
        "\n",
        "```\n",
        "def find_threshold_f1(trues, logits, eps=1e-9):\n",
        "    precision, recall, thresholds = precision_recall_curve(trues, logits)\n",
        "    f1_scores = 2 * precision * recall / (precision + recall + eps)\n",
        "    threshold = float(thresholds[np.argmax(f1_scores)])  \n",
        "    return threshold\n",
        "```\n",
        "\n",
        "trues = true labels (binarized)\n",
        "logits = row outputs of the model (sigmoid output/probabilties)\n",
        "\n",
        "For each label, there will be individual thresholds.\n",
        "\n",
        "Filter out class samples where value counts < 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hW0A51F9aDJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import h5py\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import albumentations as A\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import random\n",
        "import tarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYF2rryR_Gma"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvV07taz9qo5"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Use a fixed seed value\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnJHz7Yo9hnP"
      },
      "source": [
        "## Notebook Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuHdpdG69uvR"
      },
      "outputs": [],
      "source": [
        "class CONFIG:\n",
        "    debug = False\n",
        "    batch_size = 256\n",
        "    num_workers = 8\n",
        "    head_lr = 0.001\n",
        "    image_encoder_lr = 0.001\n",
        "    patience = 5\n",
        "    factor = 0.8\n",
        "    epochs = 20\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Image Model\n",
        "    model_name = 'resnet18'\n",
        "    image_embedding_size = 512\n",
        "\n",
        "    # Text Model\n",
        "    text_encoder_model = 'emilyalsentzer/Bio_ClinicalBERT'\n",
        "    text_tokenizer = 'emilyalsentzer/Bio_ClinicalBERT'\n",
        "    text_embedding_size = 768\n",
        "    max_length = 200\n",
        "\n",
        "    pretrained = True # for both image encoder and text encoder\n",
        "    trainable = True # for both image encoder and text encoder\n",
        "    temperature = 10.0\n",
        "    optimizer = torch.optim.Adam\n",
        "\n",
        "    # image size\n",
        "    size = 224\n",
        "\n",
        "    # for projection head; used for both image and text encoder\n",
        "    num_projection_layers = 1\n",
        "    projection_dim = 128\n",
        "    dropout = 0.0\n",
        "    ecg_sr = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQgreeeP9xCz"
      },
      "outputs": [],
      "source": [
        "_ACTIVATION_DICT = {'relu': nn.ReLU,\n",
        "                    'tanh': nn.Tanh,\n",
        "                    'none': nn.Identity,\n",
        "                    'leaky_relu': lambda: nn.LeakyReLU(negative_slope=0.2)}\n",
        "\n",
        "\n",
        "class Conv1dBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 act='relu', bn=True, dropout=None,\n",
        "                 maxpool=None, padding=None, stride=1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        if padding is None or padding == 'same':\n",
        "            padding = kernel_size // 2\n",
        "\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding, bias=not bn, stride=stride)\n",
        "        self.bn = nn.BatchNorm1d(out_channels) if bn else None\n",
        "        self.act = _ACTIVATION_DICT[act]()\n",
        "        self.dropout = None if dropout is None else nn.Dropout(dropout)\n",
        "        self.maxpool = None if maxpool is None else nn.MaxPool1d(maxpool)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "\n",
        "        if self.bn is not None:\n",
        "            x = self.bn(x)\n",
        "\n",
        "        x = self.act(x)\n",
        "\n",
        "        if self.dropout is not None:\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        if self.maxpool is not None:\n",
        "            x = self.maxpool(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class LinearBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, act='relu', bn=True, dropout=None):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear = nn.Linear(in_channels, out_channels, bias=not bn)\n",
        "        self.bn = nn.BatchNorm1d(out_channels) if bn else None\n",
        "        self.act = _ACTIVATION_DICT[act]()\n",
        "        self.dropout = None if dropout is None else nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "\n",
        "        if self.bn is not None:\n",
        "            x = self.bn(x)\n",
        "\n",
        "        x = self.act(x)\n",
        "\n",
        "        if self.dropout is not None:\n",
        "            x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, channels, kernels, bn=True, dropout=None, maxpool=2, padding=0, stride=None):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "        num_layers = len(channels)\n",
        "        if stride is None:\n",
        "            stride = [1] * num_layers\n",
        "\n",
        "        self.in_layer = Conv1dBlock(in_channels, channels[0], kernels[0], bn=bn, dropout=dropout, maxpool=maxpool, padding=padding, stride=stride[0])\n",
        "\n",
        "        conv_layers = list()\n",
        "        for i in range(1, num_layers):\n",
        "            conv_layers.append(Conv1dBlock(channels[i - 1], channels[i], kernels[i], bn=bn, dropout=dropout, maxpool=maxpool, padding=padding, stride=stride[i]))\n",
        "        self.conv_layers = nn.ModuleList(conv_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.in_layer(x)\n",
        "        for layer in self.conv_layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ECGEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 window=1280,\n",
        "                 in_channels=12,\n",
        "                 channels=(32, 32, 64, 64, 128, 128, 256, 256),\n",
        "                 kernels=(7, 7, 5, 5, 3, 3, 3, 3),\n",
        "                 linear=512,\n",
        "                 output=512):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_encoder = ConvEncoder(in_channels, channels,  kernels, bn=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inpt = torch.zeros((1, in_channels, window), dtype=torch.float32)\n",
        "            outpt = self.conv_encoder(inpt)\n",
        "            output_window = outpt.shape[2]\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv_to_linear = nn.Linear(output_window * channels[-1], linear)\n",
        "        self.act = nn.ReLU()\n",
        "        self.out_layer = nn.Linear(linear, output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_encoder(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.conv_to_linear(x)\n",
        "        x = self.act(x)\n",
        "        x = self.out_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdyetVQi960i"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI-mIalI98Xe",
        "outputId": "0eaedce6-64cb-42f9-fcab-abcc450750a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCT_6CTiD0o4"
      },
      "outputs": [],
      "source": [
        "class ImageEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = CONFIG\n",
        "        self.encoder = ECGEncoder(output=CONFIG.image_embedding_size)\n",
        "        # Add some non-linear activation here like RELU because ECG encoder already returns linear layer so this will help.\n",
        "        self.fc = nn.Linear(CONFIG.image_embedding_size, 47)  # Added this line\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.fc(x)  # Added this line\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiYKfY7JFSlu"
      },
      "source": [
        "## Model Training Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rTpAIcsFWg_"
      },
      "source": [
        "### Create X_train, y_train, X_test, y_test variables"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3NkBSIobGVmV"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
